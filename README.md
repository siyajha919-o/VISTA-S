<p align="center">
  <img src="https://img.shields.io/badge/Python-3.8%2B-blue?style=for-the-badge&logo=python" alt="Python Version">
  <img src="https://img.shields.io/badge/PyTorch-1.9%2B-orange?style=for-the-badge&logo=pytorch" alt="PyTorch Version">
  <img src="https://img.shields.io/badge/License-MIT-green?style=for-the-badge" alt="License">
</p>

<h1 align="center">VISTA-S: Visual Inference System for Target Assessment  </h1>
<h2 align="center">DualityAI Space Station Model </h2>

<p align="center">
  <b>Welcome to <strong>VISTA</strong></b> â€” an advanced, high-performance AI model designed for <b>object detection</b> with unparalleled precision.
  Inspired by the vast complexity and endless wonder of space exploration, VISTA brings cutting-edge computer vision capabilities to your fingertips. ğŸŒŒ
</p>

---

## âœ¨ Features & Highlights

- **High-Precision Object Detection:** Leverages state-of-the-art YOLOv8 for superior accuracy.
- **Optimized Performance:** Engineered for efficiency, delivering rapid inference.
- **User-Friendly Demo Application:** Easily visualize and interact with the model's capabilities.
- **Comprehensive Data Handling:** Streamlined data preparation for seamless integration.

---

## ğŸ“¸ Glimpse of VISTA in Action

![image](https://github.com/user-attachments/assets/dd193d48-df47-4687-8eda-10ce44a7e0d4)


<br>

![image](https://github.com/user-attachments/assets/da6f8f5e-2834-4007-9003-6ee1eaab3798)



---

## âš¡ï¸ Quick Setup Guide

Get VISTA up and running in a few simple steps!

### 1. Create Environment

```bash
conda env create -f environment.yaml
```

### 2. Activate Environment

```bash
conda activate VISTA
```

---

### ğŸ“¦ Data Preparation

To begin, you'll need the **Falcon Dataset**.

- **Download the Falcon Dataset:**  
  Access the dataset from [here](#). <!-- Add actual link if available -->

- **Unzip & Place:**  
  Unzip the downloaded dataset and place its contents into the following directory structure:

  ```
  data/raw/
  ```

> **Note:** The dataset is not included in this repository due to its size. Please download it manually using the provided link.

---

### ğŸ‹ï¸â€â™‚ï¸ Training the Model

Train Observo on your local machine with a single, straightforward command:

```bash
python src/train.py
```

---

### ğŸ” Running Inference

Perform object detection on any sample image effortlessly:

```bash
python src/detect.py data/raw/test/images/sample.jpg
```

---

### ğŸ–¥ï¸ Demo Application

Experience VISTA-S through its interactive web application:

1. **Navigate to App Directory:**

    ```bash
    cd app
    ```

2. **Install Requirements:**

    ```bash
    pip install -r requirements.txt
    ```

3. **Start Backend Server:**

    ```bash
    python backend.py
    ```

---

## ğŸ“Š Performance Metrics

Observo delivers exceptional performance on the Falcon dataset:

- **Precision:** ~0.97967  
- **Recall:** ~0.90879
- **mAP@0.5:** ~0.94157 
- **mAP@0.5:0.95:** ~0.88426

These impressive results were achieved using the YOLOv8 architecture.  
For an in-depth analysis, including detailed logs and visualizations, please refer to the `models/logs/yolov8_observo/` directory.

---

## ğŸ“ Project Structure

The repository is thoughtfully organized for clarity and ease of navigation:

```
â”œâ”€â”€ app/                     # Flask backend application
â”‚   â”œâ”€â”€ backend.py           # Main Flask application entry point
â”‚   â”œâ”€â”€ routes.py            # API routes and endpoints
â”‚   â”œâ”€â”€ simple_backend.py    # Simplified backend for deployment testing
â”‚   â”œâ”€â”€ requirements.txt     # Python dependencies for the app
â”‚   â””â”€â”€ templates/           # HTML templates for web interface
â”‚       â””â”€â”€ index.html       # Main web interface template
â”œâ”€â”€ config/                  # Configuration files
â”‚   â””â”€â”€ observo.yaml         # YOLO training configuration
â”œâ”€â”€ data/                    # Dataset storage (excluded from git)
â”‚   â””â”€â”€ raw/                 # Raw training data and parameters
â”‚       â”œâ”€â”€ classes.txt      # Class definitions
â”‚       â”œâ”€â”€ predict.py       # Prediction utilities
â”‚       â”œâ”€â”€ train.py         # Training utilities
â”‚       â”œâ”€â”€ visualize.py     # Visualization utilities
â”‚       â”œâ”€â”€ yolo_params.yaml # YOLO model parameters
â”‚       â””â”€â”€ data/            # Training/validation/test datasets
â”œâ”€â”€ docs/                    # Project documentation
â”‚   â””â”€â”€ report_outline.md    # Project report structure
â”œâ”€â”€ mobile/                  # React Native mobile application
â”‚   â”œâ”€â”€ src/                 # Mobile app source code
â”‚   â”‚   â”œâ”€â”€ App.js           # Main mobile app component
â”‚   â”‚   â”œâ”€â”€ api/             # API integration for mobile
â”‚   â”‚   â””â”€â”€ screens/         # Mobile app screens
â”‚   â”œâ”€â”€ package.json         # Mobile app dependencies
â”‚   â”œâ”€â”€ README.md            # Mobile app setup instructions
â”‚   â””â”€â”€ SETUP.md             # Detailed mobile setup guide
â”œâ”€â”€ models/                  # Model storage (excluded from git)
â”‚   â”œâ”€â”€ weights/             # Trained model weights (.pt files)
â”‚   â””â”€â”€ logs/                # Training logs and results
â”œâ”€â”€ notebooks/               # Jupyter notebooks (excluded from git)
â”‚   â”œâ”€â”€ EDA.ipynb            # Exploratory data analysis
â”‚   â””â”€â”€ train_yolov8.ipynb   # YOLOv8 training notebook
â”œâ”€â”€ src/                     # Core detection and training code
â”‚   â”œâ”€â”€ detect.py            # Object detection implementation
â”‚   â”œâ”€â”€ train.py             # Model training script
â”‚   â”œâ”€â”€ utils.py             # Utility functions
â”‚   â””â”€â”€ constraints.txt      # Package version constraints
â”œâ”€â”€ uploads/                 # User uploaded images (excluded from git)
â”œâ”€â”€ Web_App_frontend/        # React/TypeScript web frontend
â”‚   â”œâ”€â”€ src/                 # Frontend source code
â”‚   â”‚   â”œâ”€â”€ components/      # Reusable UI components
â”‚   â”‚   â”œâ”€â”€ pages/           # Application pages
â”‚   â”‚   â””â”€â”€ hooks/           # Custom React hooks
â”‚   â”œâ”€â”€ package.json         # Frontend dependencies
â”‚   â””â”€â”€ vite.config.ts       # Build configuration
â”œâ”€â”€ environment.yaml         # Conda environment definition
â”œâ”€â”€ requirements.txt         # Python dependencies (root level)
â”œâ”€â”€ requirements_minimal.txt # Minimal dependencies for deployment testing
â”œâ”€â”€ render.yaml              # Render deployment configuration
â”œâ”€â”€ gunicorn_config.py       # Production server configuration
â”œâ”€â”€ Procfile                 # Alternative deployment configuration
â”œâ”€â”€ .gitignore               # Git ignore patterns
â”œâ”€â”€ .gitattributes           # Git file handling rules
â”œâ”€â”€ DEPLOYMENT.md            # Deployment instructions and guides
â””â”€â”€ README.md                # Project overview and setup instructions
```

---

## âš ï¸ Important: Do NOT Commit Sensitive or Large Files

- **Model weights, logs, uploads, and raw data are excluded from version control via `.gitignore`.**
- **Never commit files in `models/weights/`, `models/logs/`, `uploads/`, or `data/raw/` to GitHub.**
- **Notebooks and environment folders are also excluded.**

---

## ğŸ¤ Contributing

We welcome contributions from the community! If you have suggestions, bug reports, or would like to contribute code:

1. **Fork** the repository.
2. **Create a new branch** for your feature or bug fix.
3. **Submit a pull request** with a clear description of your changes.

For major changes or new features, please open an issue first to discuss the proposed modifications.

---

## ğŸ“„ License

This project is open-source and licensed under the **MIT License**. See the [LICENSE](LICENSE) file for more details.

---

<p align="center">
  âœ¨ Enjoy exploring the universe of possibilities with Observo! <br>
  Feel free to â­ï¸ the repository, open issues, or contribute to its growth.<br>
  Your feedback and contributions are highly valued.
</p>

